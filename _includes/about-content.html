{% comment %}
Shared about content that can be included in both about.md and cv.md
Update this file to keep both pages in sync
{% endcomment %}

<p>I lead the <a href="https://github.com/ByteDance-Seed/Triton-distributed">Triton-distributed</a> project at ByteDance Seed.</p>

<p>I completed my Ph.D. in the School of CS at Peking University, where I was advised by <a href="https://ericlyun.github.io/">Prof. Yun Liang</a>. 
I worked with Professor <a href="https://homes.cs.washington.edu/~luisceze/">Luis Ceze</a> on LLM serving and optimization from September 2023 to January 2024 as visiting Ph.D. in <a href="https://sampl.cs.washington.edu/">SAMPL</a> at the University of Washington.
After this, I worked at DeepSeek AI for a short term as research intern.
At 2024, I joined ByteDance Seed as Machine Learning System Researcher Scientist.</p>

<p>My recent publications investigate new algorithms, abstractions, and frameworks for efficient training and inference on CPU and GPU. My research has been recognized with MICRO, ASPLOS, ISCA, HPCA, TPDS, DAC, and MLSys. I received my B.S. degree in the department of Computer Intelligence Science at Peking University.</p>

<p>I am PC member of ChinaSys; reviewer of TPDS and TACO; sub-reviewer of MICRO, PPoPP, MLSys, ICS, and ICCAD.</p>

<p><strong>Email:</strong> {{ site.author.email | replace: '@', ' [AT] ' }}</p>

<h2>Research Interests</h2>
<ul>
    <li><strong>High-performance Inference System:</strong> System design for large language and vision models</li>
    <li><strong>AI Compiler:</strong> Compiler Design for the next generation of accelerators</li>
    <li><strong>Distributed Systems:</strong> Computation-communication co-optimization and automation</li>
</ul>

<h2>Awards</h2>
<ul>
    <li><strong>July 2024</strong> Outstanding Doctoral Dissertation Award of Peking University</li>
    <li><strong>July 2024</strong> Outstanding Ph.D. Graduate of both Beijing and Peking University</li>
</ul>

